<!DOCTYPE html>

<html lang="en">

<head>
  
  <!-- hexo-inject:begin --><!-- hexo-inject:end --><title>基于朴素贝叶斯的垃圾邮件检测 - fyrhythm&#39;blog</title>
  <meta charset="UTF-8">
  <meta name="description" content="">
  <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=5">
  
  

  <link rel="shortcut icon" href="/favicon.ico" type="image/png" />
  <meta name="description" content="基于朴素贝叶斯的垃圾邮件检测一、词袋模型文本分类需要寻找文本的特征，而词袋模型就是表示文本特征的一种方式。给定一篇文档，它会有很多特征，比如文档中每个单词出现的次数，某些单词出现的位置、单词的长度等，而词袋模型只考虑一篇文档中单词出现的频率（次数），用每个单词出现的频率作为文档的特征。 与词袋模型非常类似的一个模型是词集模型(Set of Words,简称SoW)，和词袋模型唯一的不同是它仅仅考虑">
<meta property="og:type" content="article">
<meta property="og:title" content="基于朴素贝叶斯的垃圾邮件检测">
<meta property="og:url" content="http://github.com/fyering/fyering.github.io.git/2020/03/04/%E5%9F%BA%E4%BA%8E%E6%9C%B4%E7%B4%A0%E8%B4%9D%E5%8F%B6%E6%96%AF%E7%9A%84%E5%9E%83%E5%9C%BE%E9%82%AE%E4%BB%B6%E6%A3%80%E6%B5%8B/index.html">
<meta property="og:site_name" content="fyrhythm&#39;blog">
<meta property="og:description" content="基于朴素贝叶斯的垃圾邮件检测一、词袋模型文本分类需要寻找文本的特征，而词袋模型就是表示文本特征的一种方式。给定一篇文档，它会有很多特征，比如文档中每个单词出现的次数，某些单词出现的位置、单词的长度等，而词袋模型只考虑一篇文档中单词出现的频率（次数），用每个单词出现的频率作为文档的特征。 与词袋模型非常类似的一个模型是词集模型(Set of Words,简称SoW)，和词袋模型唯一的不同是它仅仅考虑">
<meta property="og:locale" content="en_US">
<meta property="og:image" content="https://s2.ax1x.com/2020/03/04/3IHTQU.png">
<meta property="og:image" content="https://s2.ax1x.com/2020/03/04/3Ib8kn.png">
<meta property="og:image" content="https://s2.ax1x.com/2020/03/04/3ILZM8.png">
<meta property="article:published_time" content="2020-03-04T11:06:37.000Z">
<meta property="article:modified_time" content="2020-03-04T11:08:15.977Z">
<meta property="article:author" content="fyrhythm">
<meta property="article:tag" content="机器学习，数据挖掘">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="https://s2.ax1x.com/2020/03/04/3IHTQU.png">
  <link rel="stylesheet" href="https://cdn.jsdelivr.net/combine/gh/nexmoe/nexmoe.github.io@latest/css/style.css,npm/highlight.js@9.15.8/styles/atom-one-dark.css,gh/nexmoe/nexmoe.github.io@latest/lib/mdui_043tiny/css/mdui.css,gh/nexmoe/nexmoe.github.io@latest/lib/iconfont/iconfont.css" crossorigin>
  
  <!--<link rel="stylesheet" href="/css/style.css?v=1583906464327">-->

  
<meta name="generator" content="Hexo 4.2.0"><!-- hexo-inject:begin --><!-- hexo-inject:end --></head>

<body class="mdui-drawer-body-left">
  
  <!-- hexo-inject:begin --><!-- hexo-inject:end --><div id="nexmoe-background">
    <div class="nexmoe-bg" style="background-image: url(https://s2.ax1x.com/2020/02/24/38jY0U.jpg)"></div>
    <div class="mdui-appbar mdui-shadow-0">
      <div class="mdui-toolbar">
        <a mdui-drawer="{target: '#drawer', swipe: true}" title="menu" class="mdui-btn mdui-btn-icon mdui-ripple"><i class="mdui-icon nexmoefont icon-menu"></i></a>
        <div class="mdui-toolbar-spacer"></div>
        <!--<a href="javascript:;" class="mdui-btn mdui-btn-icon"><i class="mdui-icon material-icons">search</i></a>-->
        <a href="/" title="fyrhythm" class="mdui-btn mdui-btn-icon"><img src="http://www.weimeitupian.com/wp-content/uploads/2018/06/2018060808341930.jpg" alt="fyrhythm"></a>
       </div>
    </div>
  </div>
  <div id="nexmoe-header">
      <div class="nexmoe-drawer mdui-drawer" id="drawer">
    <div class="nexmoe-avatar mdui-ripple">
        <a href="/" title="fyrhythm">
            <img src="http://www.weimeitupian.com/wp-content/uploads/2018/06/2018060808341930.jpg" alt="fyrhythm" alt="fyrhythm">
        </a>
    </div>
    <div class="nexmoe-count">
        <div><span>Articles</span>5</div>
        <div><span>Tags</span>2</div>
        <div><span>Categories</span>1</div>
    </div>
    <div class="nexmoe-list mdui-list" mdui-collapse="{accordion: true}">
        
        <a class="nexmoe-list-item mdui-list-item mdui-ripple" href="/" title="回到首页">
            <i class="mdui-list-item-icon nexmoefont icon-home"></i>
            <div class="mdui-list-item-content">
                回到首页
            </div>
        </a>
        
        <a class="nexmoe-list-item mdui-list-item mdui-ripple" href="/archives" title="文章归档">
            <i class="mdui-list-item-icon nexmoefont icon-container"></i>
            <div class="mdui-list-item-content">
                文章归档
            </div>
        </a>
        
    </div>
    <aside id="nexmoe-sidebar">
  
  <div class="nexmoe-widget-wrap">
    <div class="nexmoe-widget nexmoe-search">
        <form id="search_form" action_e="https://cn.bing.com/search?q=site:nexmoe.com" onsubmit="return search();">
            <label><input id="search_value" name="q" type="search" placeholder="Search"></label>
        </form>
    </div>
</div>
  
  <div class="nexmoe-widget-wrap">
    <h3 class="nexmoe-widget-title">Social</h3>
    <div class="nexmoe-widget nexmoe-social">
        <a class="mdui-ripple" href="https://space.bilibili.com/133000099" target="_blank" mdui-tooltip="{content: '哔哩哔哩'}" style="color: rgb(231, 106, 141);background-color: rgba(231, 106, 141, .15);">
            <i class="nexmoefont icon-bilibili"></i>
        </a><a class="mdui-ripple" href="https://github.com/fyering" target="_blank" mdui-tooltip="{content: 'GitHub'}" style="color: rgb(25, 23, 23);background-color: rgba(25, 23, 23, .15);">
            <i class="nexmoefont icon-github"></i>
        </a>
    </div>
</div>
  
  
  <div class="nexmoe-widget-wrap">
    <h3 class="nexmoe-widget-title">Categories</h3>
    <div class="nexmoe-widget">

      <ul class="category-list">

        


        

        

        <li class="category-list-item">
          <a class="category-list-link" href="/categories/数据挖掘与机器学习/">数据挖掘与机器学习</a>
          <span class="category-list-count">4</span>
        </li>

        
      </ul>

    </div>
  </div>


  
  
  <div class="nexmoe-widget-wrap">
    <h3 class="nexmoe-widget-title">Tag Cloud</h3>
    <div id="randomtagcloud" class="nexmoe-widget tagcloud">
      <a href="/tags/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/" style="font-size: 10px;">机器学习</a> <a href="/tags/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%EF%BC%8C%E6%95%B0%E6%8D%AE%E6%8C%96%E6%8E%98/" style="font-size: 20px;">机器学习，数据挖掘</a>
    </div>
    
  </div>

  
  
  <div class="nexmoe-widget-wrap">
    <h3 class="nexmoe-widget-title">Archive</h3>
    <div class="nexmoe-widget">
      <ul class="archive-list"><li class="archive-list-item"><a class="archive-list-link" href="/archives/2020/03/">March 2020</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2020/02/">February 2020</a></li></ul>
    </div>
  </div>


  
</aside>
    <div class="nexmoe-copyright">
        &copy; 2020 fyrhythm
        Powered by <a href="http://hexo.io/" target="_blank">Hexo</a>
        & <a href="https://nexmoe.com/hexo-theme-nexmoe.html" target="_blank">Nexmoe</a>
    </div>
</div><!-- .nexmoe-drawer -->
  </div>
  <div id="nexmoe-content">
    <div class="nexmoe-primary">
        <div class="nexmoe-post">
  
      <div class="nexmoe-post-cover" style="padding-bottom: 66.66666666666666%;"> 
          <img data-src="https://s2.ax1x.com/2020/02/24/38jY0U.jpg" data-sizes="auto" alt="基于朴素贝叶斯的垃圾邮件检测" class="lazyload">
          <h1>基于朴素贝叶斯的垃圾邮件检测</h1>
      </div>
  
  
  <div class="nexmoe-post-meta" style="margin:10px 0!important;">
    <a><i class="nexmoefont icon-calendar-fill"></i>2020年03月04日</a>
    <a><i class="nexmoefont icon-areachart"></i>2.5k 字</a>
    <a><i class="nexmoefont icon-time-circle-fill"></i>大概 11 分钟</a>
</div>

  <div class="nexmoe-post-right">
    
      <div class="nexmoe-fixed">
        <div class="nexmoe-valign">
            <div class="nexmoe-toc">
                <ol class="toc"><li class="toc-item toc-level-1"><a class="toc-link" href="#基于朴素贝叶斯的垃圾邮件检测"><span class="toc-number">1.</span> <span class="toc-text">基于朴素贝叶斯的垃圾邮件检测</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#一、词袋模型"><span class="toc-number">1.1.</span> <span class="toc-text">一、词袋模型</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#1-1分词"><span class="toc-number">1.2.</span> <span class="toc-text">1.1分词</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#1-2-构造单词集合"><span class="toc-number">1.3.</span> <span class="toc-text">1.2 构造单词集合</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#1-3词袋模型"><span class="toc-number">1.4.</span> <span class="toc-text">1.3词袋模型</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#1-4训练贝叶斯模型"><span class="toc-number">1.5.</span> <span class="toc-text">1.4训练贝叶斯模型</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#1-5测试集分类"><span class="toc-number">1.6.</span> <span class="toc-text">1.5测试集分类</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#1-6-完整代码"><span class="toc-number">1.7.</span> <span class="toc-text">1.6 完整代码</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#1-7运行结果"><span class="toc-number">1.8.</span> <span class="toc-text">1.7运行结果</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#1-8-评价"><span class="toc-number">1.9.</span> <span class="toc-text">1.8 评价</span></a></li></ol></li></ol>
            </div>
        </div>
      </div>
    
  </div>

  <article>
    <h1 id="基于朴素贝叶斯的垃圾邮件检测"><a href="#基于朴素贝叶斯的垃圾邮件检测" class="headerlink" title="基于朴素贝叶斯的垃圾邮件检测"></a>基于朴素贝叶斯的垃圾邮件检测</h1><h2 id="一、词袋模型"><a href="#一、词袋模型" class="headerlink" title="一、词袋模型"></a>一、词袋模型</h2><p>文本分类需要寻找文本的特征，而词袋模型就是表示文本特征的一种方式。给定一篇文档，它会有很多特征，比如文档中每个单词出现的次数，某些单词出现的位置、单词的长度等，而词袋模型只考虑一篇文档中单词出现的频率（次数），用每个单词出现的频率作为文档的特征。</p>
<p>与词袋模型非常类似的一个模型是<strong>词集模型(Set of Words,简称SoW)</strong>，和词袋模型唯一的不同是它仅仅考虑词是否在文本中出现，而不考虑词频。也就是一个词在文本中出现1次和多次特征处理是一样的。在大多数时候，我们使用词袋模型，后面的讨论也是以词袋模型为主。</p>
<p>词袋模型有很大的局限性，因为它仅仅考虑了词频，没有考虑上下文的关系，因此会丢失一部分文本的语义。但是大多数时候，如果我们的目的是分类聚类，则词袋模型表现的很好。</p>
<p>词袋模型的三部曲：<strong>分词（tokenizing），统计修订词特征值（counting）与标准化（normalizing）。</strong></p>
<h2 id="1-1分词"><a href="#1-1分词" class="headerlink" title="1.1分词"></a>1.1分词</h2><p>使用正则表达式</p>
<p>\W<em>：表示匹配所有除字母数字下划线的所有字符即特殊字符，\</em>表示可以匹配0和多次</p>
<p>\d+：表示匹配0-9的数字，可匹配1到无数次</p>
<p>使用python 的re模块对文本进行分词，如下：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">file_object=open(filepath)</span><br><span class="line">   file_content=file_object.read()</span><br><span class="line">   str_nonnum=re.sub(<span class="string">r'\d+'</span>,<span class="string">''</span>,file_content)<span class="comment">#替换所有数字为空</span></span><br><span class="line">   token_list=re.split(<span class="string">r'\W'</span>,str_nonnum)<span class="comment">#使用特殊字符作为间隔划分单词</span></span><br><span class="line">   token_list=[token.lower() <span class="keyword">for</span> token <span class="keyword">in</span> token_list <span class="keyword">if</span> token!=<span class="string">''</span>]<span class="comment">#消除’‘空字符</span></span><br><span class="line">   print(token_list)</span><br></pre></td></tr></table></figure>
<h2 id="1-2-构造单词集合"><a href="#1-2-构造单词集合" class="headerlink" title="1.2 构造单词集合"></a>1.2 构造单词集合</h2><p>使用python的set集合，是一个不重复的元素集。对所有文档进行分词处理，构造无重复单词的单词库，单词库即训练集样本的所有特征。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#对所有邮件进行分词处理，并形成一个整体的词汇表</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">bagOfWord</span><span class="params">(doclist)</span>:</span></span><br><span class="line">    wordsList=set([])</span><br><span class="line">    <span class="keyword">for</span> wordlist <span class="keyword">in</span> doclist:</span><br><span class="line">        wordsList=wordsList|set(wordlist)<span class="comment">#求并集</span></span><br><span class="line">    print(wordsList)</span><br><span class="line">    <span class="keyword">return</span> list(wordsList)</span><br></pre></td></tr></table></figure>
<h2 id="1-3词袋模型"><a href="#1-3词袋模型" class="headerlink" title="1.3词袋模型"></a>1.3词袋模型</h2><p>为每个训练样本即邮件文本构造词袋模型，得到属于该样本文档的文档向量，向量长度即词袋中所有单词的数量。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">vecofwords</span><span class="params">(wordslist,inputset)</span>:</span></span><br><span class="line">    returnvec=np.zeros(len(wordslist)) <span class="comment">#创建一个长度和词汇表一样的向量，并置初值为0</span></span><br><span class="line">    <span class="keyword">for</span> word <span class="keyword">in</span> inputset:</span><br><span class="line">        <span class="keyword">if</span> word <span class="keyword">in</span> wordslist:</span><br><span class="line">            returnvec[wordslist.index(word)]+=<span class="number">1</span><span class="comment">#累加单词出现的次数</span></span><br><span class="line">    <span class="keyword">return</span> returnvec</span><br></pre></td></tr></table></figure>
<h2 id="1-4训练贝叶斯模型"><a href="#1-4训练贝叶斯模型" class="headerlink" title="1.4训练贝叶斯模型"></a>1.4训练贝叶斯模型</h2><p>将输入的训练样本构造成文档向量后，可以根据这些文档向量构造一个训练矩阵，矩阵的行数为训练样本数量，矩阵列数为特征属性数量。输入训练矩阵和训练样本的标签数组，就可以训练模型了。</p>
<p><strong>unknow words的情形</strong></p>
<p>假设只考虑文本二分类：将文档分成 positve类别，或者negative类别，C={positive, negative}</p>
<p>在训练数据集中，类别为positive的所有文档 都没有 包含 单词wi = fantastic（fantastic可能出现在类别为negative的文档中）那么 count(wi=fantastic，ci=positive)=0 。那么：</p>
<p><img data-sizes="auto" data-src="https://s2.ax1x.com/2020/03/04/3IHTQU.png" alt="3IHTQU.png" class="lazyload"></p>
<p>如果文档d中有个单词在类别为c的训练数据集文档中从未出现过，那文档d被分类到类别c的概率为0，尽管文档d中还有一些其他单词（特征），而这些单词所代表的特征认为文档d应该被分类 到 类别c中。</p>
<p>解决方法：拉普拉斯平滑</p>
<p><img data-sizes="auto" data-src="https://s2.ax1x.com/2020/03/04/3Ib8kn.png" alt="3Ib8kn.png" class="lazyload"></p>
<p>其中|V|是词库中所有单词的个数。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">NBtraining</span><span class="params">(trianMatrix,trianClasses)</span>:</span></span><br><span class="line">    <span class="comment">#得到训练样本的数量</span></span><br><span class="line">    trainNum=len(trianClasses)</span><br><span class="line">    <span class="comment">#得到样本的特征属性数量</span></span><br><span class="line">    wordsnum=len(trianMatrix[<span class="number">0</span>])</span><br><span class="line">    <span class="comment">#垃圾邮件的先验概率</span></span><br><span class="line">    plj=sum(trianClasses)/float(trainNum)</span><br><span class="line">    <span class="comment">#垃圾邮件的似然概率分子数组:P(W0|C1),P(W1|C1),P(W2|C1).....</span></span><br><span class="line">    pspam=np.ones(wordsnum)</span><br><span class="line">     <span class="comment">#非垃圾邮件的似然概率分子组:P(W0|C0),P(W1|C0),P(W2|C0).....</span></span><br><span class="line">    pham=np.ones(wordsnum)</span><br><span class="line">    <span class="comment">#似然概率的分母</span></span><br><span class="line">    totalsapm=wordsnum</span><br><span class="line">    totalham=wordsnum<span class="comment">#使用拉普拉斯平滑</span></span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> range(trainNum):</span><br><span class="line">        <span class="keyword">if</span> trianClasses[i]==<span class="number">1</span>:<span class="comment">#如果该样本是垃圾邮件,则计算垃圾邮件的似然概率p(W0|C)...</span></span><br><span class="line">            pspam+=trianMatrix[i]</span><br><span class="line">            totalsapm+=sum(trianMatrix[i])</span><br><span class="line">        <span class="keyword">if</span> trianClasses[i]==<span class="number">0</span>:<span class="comment">#非垃圾邮件</span></span><br><span class="line">            pham+=trianMatrix[i]</span><br><span class="line">            totalham+=sum(trianMatrix[i])</span><br><span class="line">    <span class="comment">#为了避免溢出，使用log进行对数化</span></span><br><span class="line">    pspamvec=np.log(pspam/totalsapm)</span><br><span class="line">    phamvec=np.log(pham/totalham)</span><br><span class="line">    <span class="keyword">return</span> pspamvec,phamvec,plj</span><br></pre></td></tr></table></figure>
<h2 id="1-5测试集分类"><a href="#1-5测试集分类" class="headerlink" title="1.5测试集分类"></a>1.5测试集分类</h2><p>使用训练出来的模型对测试集进行分类：</p>
<p>testdata是一个测试样本的文档向量，将该文档向量与似然概率数组一一对应相乘</p>
<p>例如，如果testdata中某个单词出现次数为2，则乘以似然概率数组中对应的值，假如是log(P(Wi/C1))，则相乘的结果是2*log(P(Wi|C1))=log(P(Wi|C1)^2),此时假设某个单词出现在文档中不同位置时的概率时一样的，所以P（Wi|C1）的平方。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">ef classifier(testdata,pspamvec,phamvec,plj):</span><br><span class="line">    p1=sum(testdata*pspamvec)+np.log(plj)</span><br><span class="line">    p0=sum(testdata*phamvec)+np.log(<span class="number">1</span>-plj)</span><br><span class="line">    <span class="keyword">if</span> p1&gt;p0:</span><br><span class="line">        <span class="keyword">return</span> <span class="number">1</span></span><br><span class="line">    <span class="keyword">else</span> :</span><br><span class="line">        <span class="keyword">return</span> <span class="number">0</span></span><br></pre></td></tr></table></figure>
<h2 id="1-6-完整代码"><a href="#1-6-完整代码" class="headerlink" title="1.6 完整代码"></a>1.6 完整代码</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> re</span><br><span class="line"><span class="keyword">import</span> os</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span>  random</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">splittxt</span><span class="params">(filepath)</span>:</span></span><br><span class="line">    file_object=open(filepath)</span><br><span class="line">    file_content=file_object.read()</span><br><span class="line">    str_nonnum=re.sub(<span class="string">r'\d+'</span>,<span class="string">''</span>,file_content)<span class="comment">#替换所有数字为空</span></span><br><span class="line">    token_list=re.split(<span class="string">r'\W'</span>,str_nonnum)<span class="comment">#使用特殊字符作为间隔划分单词</span></span><br><span class="line">    token_list=[token.lower() <span class="keyword">for</span> token <span class="keyword">in</span> token_list <span class="keyword">if</span> token!=<span class="string">''</span>]<span class="comment">#消除’‘空字符</span></span><br><span class="line">    print(token_list)</span><br><span class="line">    <span class="keyword">return</span> token_list</span><br><span class="line"></span><br><span class="line"><span class="comment">#对所有邮件进行分词处理，并形成一个整体的词汇表</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">bagOfWord</span><span class="params">(doclist)</span>:</span></span><br><span class="line">    wordsList=set([])</span><br><span class="line">    <span class="keyword">for</span> wordlist <span class="keyword">in</span> doclist:</span><br><span class="line">        wordsList=wordsList|set(wordlist)<span class="comment">#求并集</span></span><br><span class="line">    print(wordsList)</span><br><span class="line">    <span class="keyword">return</span> list(wordsList)</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">vecofwords</span><span class="params">(wordslist,inputset)</span>:</span></span><br><span class="line">    returnvec=np.zeros(len(wordslist)) <span class="comment">#创建一个长度和词汇表一样的向量，并置初值为0</span></span><br><span class="line">    <span class="keyword">for</span> word <span class="keyword">in</span> inputset:</span><br><span class="line">        <span class="keyword">if</span> word <span class="keyword">in</span> wordslist:</span><br><span class="line">            returnvec[wordslist.index(word)]+=<span class="number">1</span></span><br><span class="line">    <span class="keyword">return</span> returnvec</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">NBtraining</span><span class="params">(trianMatrix,trianClasses)</span>:</span></span><br><span class="line">    <span class="comment">#得到训练样本的数量</span></span><br><span class="line">    trainNum=len(trianClasses)</span><br><span class="line">    <span class="comment">#得到样本的特征属性数量</span></span><br><span class="line">    wordsnum=len(trianMatrix[<span class="number">0</span>])</span><br><span class="line">    <span class="comment">#垃圾邮件的先验概率</span></span><br><span class="line">    plj=sum(trianClasses)/float(trainNum)</span><br><span class="line">    pspam=np.ones(wordsnum)</span><br><span class="line">    pham=np.ones(wordsnum)</span><br><span class="line">    totalsapm=wordsnum</span><br><span class="line">    totalham=wordsnum<span class="comment">#拉普拉斯平滑</span></span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> range(trainNum):</span><br><span class="line">        <span class="keyword">if</span> trianClasses[i]==<span class="number">1</span>:<span class="comment">#如果该样本是垃圾邮件,则计算垃圾邮件的似然概率p(W0|C)...</span></span><br><span class="line">            pspam+=trianMatrix[i]</span><br><span class="line">            totalsapm+=sum(trianMatrix[i])</span><br><span class="line">        <span class="keyword">if</span> trianClasses[i]==<span class="number">0</span>:<span class="comment">#非垃圾邮件</span></span><br><span class="line">            pham+=trianMatrix[i]</span><br><span class="line">            totalham+=sum(trianMatrix[i])</span><br><span class="line">    <span class="comment">#w为了避免溢出，使用log进行对数化</span></span><br><span class="line"></span><br><span class="line">    pspamvec=np.log(pspam/totalsapm)</span><br><span class="line">    phamvec=np.log(pham/totalham)</span><br><span class="line">    <span class="keyword">return</span> pspamvec,phamvec,plj</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">classifier</span><span class="params">(testdata,pspamvec,phamvec,plj)</span>:</span></span><br><span class="line">    p1=sum(testdata*pspamvec)+np.log(plj)</span><br><span class="line">    p0=sum(testdata*phamvec)+np.log(<span class="number">1</span>-plj)</span><br><span class="line">    <span class="keyword">if</span> p1&gt;p0:</span><br><span class="line">        <span class="keyword">return</span> <span class="number">1</span></span><br><span class="line">    <span class="keyword">else</span> :</span><br><span class="line">        <span class="keyword">return</span> <span class="number">0</span></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">testNBClassifier</span><span class="params">()</span>:</span></span><br><span class="line">    docList = []</span><br><span class="line">    classList = []</span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> range(<span class="number">1</span>, <span class="number">26</span>):  <span class="comment"># 遍历25个txt文件</span></span><br><span class="line">        wordList = splittxt(<span class="string">'D:\\Course\\数据挖掘\\实验\\实验二\\email(1)\\email\\spam\\%d.txt'</span> % i)  <span class="comment"># 读取每个垃圾邮件，并字符串转换成字符串列表</span></span><br><span class="line">        docList.append(wordList)</span><br><span class="line">        classList.append(<span class="number">1</span>)  <span class="comment"># 标记垃圾邮件，1表示垃圾文件</span></span><br><span class="line">        wordList = splittxt(<span class="string">'D:\\Course\\数据挖掘\\实验\\实验二\\email(1)\\email\\ham\\%d.txt'</span> % i)  <span class="comment"># 读取每个非垃圾邮件，并字符串转换成字符串列表</span></span><br><span class="line">        docList.append(wordList)</span><br><span class="line">        classList.append(<span class="number">0</span>)  <span class="comment"># 标记正常邮件，0表示正常文件</span></span><br><span class="line">    vocabList = bagOfWord(docList)  <span class="comment"># 创建词汇表，不重复</span></span><br><span class="line">    trainingSet = list(range(<span class="number">50</span>))<span class="comment">#0-49</span></span><br><span class="line">    testSet = []  <span class="comment"># 创建存储训练集的索引值的列表和测试集的索引值的列表</span></span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> range(<span class="number">10</span>):  <span class="comment"># 从50个邮件中，随机挑选出40个作为训练集,10个做测试集</span></span><br><span class="line">        randIndex = int(random.uniform(<span class="number">0</span>, len(trainingSet)))  <span class="comment"># 随机选取索索引值</span></span><br><span class="line">        testSet.append(trainingSet[randIndex])  <span class="comment"># 添加测试集的索引值</span></span><br><span class="line">        <span class="keyword">del</span> (trainingSet[randIndex])  <span class="comment"># 在训练集列表中删除添加到测试集的索引值</span></span><br><span class="line">    trainMat = []</span><br><span class="line">    trainClasses = []  <span class="comment"># 创建训练集矩阵和训练集类别标签系向量</span></span><br><span class="line">    <span class="keyword">for</span> docIndex <span class="keyword">in</span> trainingSet:  <span class="comment"># 遍历训练集</span></span><br><span class="line">        trainMat.append(vecofwords(vocabList, docList[docIndex]))  <span class="comment"># 将生成的词集模型添加到训练矩阵中</span></span><br><span class="line">        trainClasses.append(classList[docIndex])  <span class="comment"># 将类别添加到训练集类别标签系向量中</span></span><br><span class="line">    p1V, p0V, pSpam = NBtraining(np.array(trainMat), np.array(trainClasses))  <span class="comment"># 训练朴素贝叶斯模型</span></span><br><span class="line">    errorCount = <span class="number">0</span>  <span class="comment"># 错误分类计数</span></span><br><span class="line">    <span class="keyword">for</span> docIndex <span class="keyword">in</span> testSet:  <span class="comment"># 遍历测试集</span></span><br><span class="line">        wordVector = vecofwords(vocabList, docList[docIndex])  <span class="comment"># 测试集的词集模型</span></span><br><span class="line">        <span class="keyword">if</span> classifier(np.array(wordVector), p1V, p0V, pSpam) != classList[docIndex]:  <span class="comment"># 如果分类错误</span></span><br><span class="line">            errorCount += <span class="number">1</span>  <span class="comment"># 错误计数加1</span></span><br><span class="line">            print(<span class="string">"分类错误的测试集："</span>, docList[docIndex])</span><br><span class="line">    print(<span class="string">'错误率：%.2f%%'</span> % (float(errorCount) / len(testSet) * <span class="number">100</span>))</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">'__main__'</span>:</span><br><span class="line">    testNBClassifier()</span><br></pre></td></tr></table></figure>
<h2 id="1-7运行结果"><a href="#1-7运行结果" class="headerlink" title="1.7运行结果"></a>1.7运行结果</h2><p><img data-sizes="auto" data-src="https://s2.ax1x.com/2020/03/04/3ILZM8.png" alt="3ILZM8.png" class="lazyload"></p>
<h2 id="1-8-评价"><a href="#1-8-评价" class="headerlink" title="1.8 评价"></a>1.8 评价</h2><p>朴素贝叶斯的主要优点有：</p>
<p>1）朴素贝叶斯模型发源于古典数学理论，有稳定的分类效率。</p>
<p>2）对小规模的数据表现很好，能个处理多分类任务，适合增量式训练，尤其是数据量超出内存时，我们可以一批批的去增量训练。</p>
<p>3）对缺失数据不太敏感，算法也比较简单，常用于文本分类。</p>
<p>朴素贝叶斯的主要缺点有：</p>
<p>1） 理论上，朴素贝叶斯模型与其他分类方法相比具有最小的误差率。但是实际上并非总是如此，这是因为朴素贝叶斯模型假设属性之间相互独立，这个假设在实际应用中往往是不成立的，在属性个数比较多或者属性之间相关性较大时，分类效果不好。而在属性相关性较小时，朴素贝叶斯性能最为良好。对于这一点，有半朴素贝叶斯之类的算法通过考虑部分关联性适度改进。</p>
<p>2）需要知道先验概率，且先验概率很多时候取决于假设，假设的模型可以有很多种，因此在某些时候会由于假设的先验模型的原因导致预测效果不佳。</p>
<p>3）由于我们是通过先验和数据来决定后验的概率从而决定分类，所以分类决策存在一定的错误率。</p>
<p>4）对输入数据的表达形式很敏感。</p>

  </article>

  <div class="nexmoe-post-meta">
    
        <a class="nexmoefont icon-appstore-fill -link" href="/categories/%E6%95%B0%E6%8D%AE%E6%8C%96%E6%8E%98%E4%B8%8E%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/">数据挖掘与机器学习</a>
    
    
        <a class="nexmoefont icon-tag-fill -link" href="/tags/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%EF%BC%8C%E6%95%B0%E6%8D%AE%E6%8C%96%E6%8E%98/" rel="tag">机器学习，数据挖掘</a>
    
</div>

  <div class="nexmoe-post-footer">
    
      
  <div class="nexmoe-post-copyright">
    <strong>Author：</strong>fyrhythm<br>
    <strong>Link：</strong><a href="http://github.com/fyering/fyering.github.io.git/2020/03/04/%E5%9F%BA%E4%BA%8E%E6%9C%B4%E7%B4%A0%E8%B4%9D%E5%8F%B6%E6%96%AF%E7%9A%84%E5%9E%83%E5%9C%BE%E9%82%AE%E4%BB%B6%E6%A3%80%E6%B5%8B/" title="http:&#x2F;&#x2F;github.com&#x2F;fyering&#x2F;fyering.github.io.git&#x2F;2020&#x2F;03&#x2F;04&#x2F;%E5%9F%BA%E4%BA%8E%E6%9C%B4%E7%B4%A0%E8%B4%9D%E5%8F%B6%E6%96%AF%E7%9A%84%E5%9E%83%E5%9C%BE%E9%82%AE%E4%BB%B6%E6%A3%80%E6%B5%8B&#x2F;" target="_blank" rel="noopener">http:&#x2F;&#x2F;github.com&#x2F;fyering&#x2F;fyering.github.io.git&#x2F;2020&#x2F;03&#x2F;04&#x2F;%E5%9F%BA%E4%BA%8E%E6%9C%B4%E7%B4%A0%E8%B4%9D%E5%8F%B6%E6%96%AF%E7%9A%84%E5%9E%83%E5%9C%BE%E9%82%AE%E4%BB%B6%E6%A3%80%E6%B5%8B&#x2F;</a><br>
    
      <strong>版权声明：</strong>本文采用 <a href="https://creativecommons.org/licenses/by-nc-sa/3.0/cn/deed.zh" target="_blank">CC BY-NC-SA 3.0 CN</a> 协议进行许可
    
  </div>


    
    <section class="nexmoe-comment">
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/gitalk@1.5.0/dist/gitalk.min.css">
<div id="gitalk"></div>
<script src="https://cdn.jsdelivr.net/npm/gitalk@1.5.0/dist/gitalk.min.js"></script>
<script type="text/javascript">
    var gitalk = new Gitalk({
        clientID: '80b2453b6d5f37ad6225',
        clientSecret: '43e99fa852795c9a7b3eb924b2558c64b84bbdeb',
        id: window.location.pathname,
        repo: 'nexmoe.github.io',
        owner: 'nexmoe',
        admin: 'nexmoe'
    })
    gitalk.render('gitalk')
</script>
</section>
  </div>
</div>
    </div>
  </div>
  <script src="https://cdn.jsdelivr.net/combine/npm/lazysizes@5.1.0/lazysizes.min.js,gh/highlightjs/cdn-release@9.15.8/build/highlight.min.js,npm/mdui@0.4.3/dist/js/mdui.min.js,gh/nexmoe/nexmoe.github.io@latest/js/app.js"></script>
<script>hljs.initHighlightingOnLoad();</script>
<!--<script src="/js/app.js?v=1583906464331"></script>-->


    <script src="https://cdn.jsdelivr.net/gh/xtaodada/xtaodada.github.io@0.0.2/copy.js"></script>


 
<script> 
!function(e,t,a){function n(){c(".heart{width: 10px;height: 10px;position: fixed;background: #f00;transform: rotate(45deg);-webkit-transform: rotate(45deg);-moz-transform: rotate(45deg);}.heart:after,.heart:before{content: '';width: inherit;height: inherit;background: inherit;border-radius: 50%;-webkit-border-radius: 50%;-moz-border-radius: 50%;position: fixed;}.heart:after{top: -5px;}.heart:before{left: -5px;}"),o(),r()}function r(){for(var e=0;e<d.length;e++)d[e].alpha<=0?(t.body.removeChild(d[e].el),d.splice(e,1)):(d[e].y--,d[e].scale+=.004,d[e].alpha-=.013,d[e].el.style.cssText="left:"+d[e].x+"px;top:"+d[e].y+"px;opacity:"+d[e].alpha+";transform:scale("+d[e].scale+","+d[e].scale+") rotate(45deg);background:"+d[e].color+";z-index:99999");requestAnimationFrame(r)}function o(){var t="function"==typeof e.onclick&&e.onclick;e.onclick=function(e){t&&t(),i(e)}}function i(e){var a=t.createElement("div");a.className="heart",d.push({el:a,x:e.clientX-5,y:e.clientY-5,scale:1,alpha:1,color:s()}),t.body.appendChild(a)}function c(e){var a=t.createElement("style");a.type="text/css";try{a.appendChild(t.createTextNode(e))}catch(t){a.styleSheet.cssText=e}t.getElementsByTagName("head")[0].appendChild(a)}function s(){return"rgb("+~~(255*Math.random())+","+~~(255*Math.random())+","+~~(255*Math.random())+")"}var d=[];e.requestAnimationFrame=function(){return e.requestAnimationFrame||e.webkitRequestAnimationFrame||e.mozRequestAnimationFrame||e.oRequestAnimationFrame||e.msRequestAnimationFrame||function(e){setTimeout(e,1e3/60)}}(),n()}(window,document);
</script>

  





<script type="text/x-mathjax-config">
    MathJax.Hub.Config({
        tex2jax: {
            inlineMath: [ ["$","$"], ["\\(","\\)"] ],
            skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code'],
            processEscapes: true
        }
    });
    MathJax.Hub.Queue(function() {
        var all = MathJax.Hub.getAllJax();
        for (var i = 0; i < all.length; ++i)
            all[i].SourceElement().parentNode.className += ' has-jax';
    });
</script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js?config=TeX-MML-AM_CHTML"></script><!-- hexo-inject:begin --><!-- hexo-inject:end -->
</body>

</html>
